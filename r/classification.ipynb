{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15410770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download ()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86359069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c3516d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"renttherunway_final_data.json.gz\",lines = True)\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61533367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kl/8j13qjxs4fd9fz6_ng5b4qpc0000gn/T/ipykernel_33359/201975335.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_df[\"review_total\"] = total_df[\"review_summary\"]+ \" \" +total_df[\"review_text\"]\n"
     ]
    }
   ],
   "source": [
    "total_df = df[[\"review_text\",\"review_summary\",\"rating\",\"size\",\"fit\"]]\n",
    "total_df[\"review_total\"] = total_df[\"review_summary\"]+ \" \" +total_df[\"review_text\"]\n",
    "total_df=total_df.drop([\"review_text\",\"review_summary\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95b78a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc1f7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fit(fit):\n",
    "    if fit == 'large':\n",
    "        out = 0\n",
    "    elif fit == 'small':\n",
    "        out = 1\n",
    "    else:\n",
    "        out = 2\n",
    "    return out\n",
    "total_df[\"fit\"] = total_df[\"fit\"].apply(lambda x: convert_fit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e7b747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating(rating):\n",
    "    return rating/2-1\n",
    "total_df[\"rating\"] = total_df[\"rating\"].apply(lambda x: convert_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fafa19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "total_df['review_total']= total_df['review_total'].apply(lambda x:remove_punctuation(x))\n",
    "def tokenization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "#applying function to the column\n",
    "total_df['review_total']= total_df['review_total'].apply(lambda x: tokenization(x))\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "total_df['review_total']= total_df['review_total'].apply(lambda x:remove_stopwords(x))\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "total_df['review_total']=total_df['review_total'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49de4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(text):\n",
    "    string = ''\n",
    "    for i in range(len(text)):\n",
    "        string += text[i]\n",
    "        string += ' '\n",
    "    return string\n",
    "total_df['review_total']=total_df['review_total'].apply(lambda x:combine(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"sentiment_score\"] = total_df[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_review(review):\n",
    "    sent_dict = sid.polarity_scores(review)\n",
    "    return sent_dict['compound']\n",
    "total_df[\"sentiment_score\"] = total_df[\"review_total\"].apply(lambda x: convert_review(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa19474",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df=total_df.drop([\"review_total\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = total_df[[\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97157989",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df=total_df.drop([\"rating\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51661ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid,y_train, y_valid = train_test_split(total_df,label_df,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=3,eta=0.3,silent=1,objective='multi:softprob',num_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = xgb.predict(X_train)\n",
    "pred = xgb.predict(X_valid)\n",
    "y_train_arr = y_train[\"rating\"].to_numpy()\n",
    "y_valid_arr = y_valid[\"rating\"].to_numpy()\n",
    "acc_xgbfits = (fits == y_train_arr).sum().astype(float) / len(fits)*100\n",
    "acc_xgb = (pred == y_valid_arr).sum().astype(float) / len(pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc493d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8827909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = (knn_predictions == y_valid_arr).sum().astype(float) / len(knn_predictions)*100\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = (rf_predictions == y_valid_arr).sum().astype(float) / len(rf_predictions)*100\n",
    "acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da814816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "snn_classifier = MLPClassifier()\n",
    "snn_classifier.fit(X_train, y_train)\n",
    "snn_predictions = snn_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab178f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_snn = (snn_predictions == y_valid_arr).sum().astype(float) / len(snn_predictions)*100\n",
    "acc_snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_classifier = MLPClassifier(hidden_layer_sizes = [100]*5)\n",
    "dnn_classifier.fit(X_train, y_train)\n",
    "dnn_predictions = dnn_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b378a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dnn = (dnn_predictions == y_valid_arr).sum().astype(float) / len(dnn_predictions)*100\n",
    "acc_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06165a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "dnns_classifier = OneVsRestClassifier(MLPClassifier(hidden_layer_sizes = [100]*5))\n",
    "dnns_classifier.fit(np.array(X_train), y_train)\n",
    "dnns_predictions_labels = dnns_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe94438",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dnn = (dnns_predictions_labels == y_valid_arr).sum().astype(float) / len(dnns_predictions_labels)*100\n",
    "acc_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier = SVC(decision_function_shape='ovr')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_predictions_labels = svm_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0343fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svm = (svm_predictions_labels == y_valid_arr).sum().astype(float) / len(svm_predictions_labels)*100\n",
    "acc_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "xbg_predictions_labels = xgb_classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_xgb = (xbg_predictions_labels == y_valid_arr).sum().astype(float) / len(xbg_predictions_labels)*100\n",
    "acc_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de736e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27fc8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3aec5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "label_df = total_df[[\"rating\"]]\n",
    "x_df = total_df[[\"review_total\"]]\n",
    "\n",
    "x_arr = x_df[\"review_total\"].to_numpy()\n",
    "y_arr = label_df[\"rating\"].to_numpy()\n",
    "\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(x_arr,y_arr,test_size=0.2)\n",
    "\n",
    "X_train_tf = tf_idf.fit_transform(X_train)\n",
    "\n",
    "X_train_tf = tf_idf.transform(X_train)\n",
    "\n",
    "X_test_tf = tf_idf.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7b8064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:14:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1667849653518/work/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.03      0.06       203\n",
      "         1.0       0.30      0.05      0.08       575\n",
      "         2.0       0.45      0.11      0.17      2184\n",
      "         3.0       0.54      0.30      0.39     10608\n",
      "         4.0       0.74      0.94      0.83     24923\n",
      "\n",
      "    accuracy                           0.70     38493\n",
      "   macro avg       0.45      0.29      0.31     38493\n",
      "weighted avg       0.66      0.70      0.65     38493\n",
      "\n",
      "[[    7    20    36    62    78]\n",
      " [    7    26   117   224   201]\n",
      " [    9    30   233  1005   907]\n",
      " [    7    10   109  3230  7252]\n",
      " [    1     0    19  1471 23432]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=3,eta=0.3,silent=1,objective='multi:softprob',num_class=3)\n",
    "\n",
    "model = xgb.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test_tf)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "894fbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4489170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       203\n",
      "         1.0       0.00      0.00      0.00       575\n",
      "         2.0       0.00      0.00      0.00      2184\n",
      "         3.0       0.46      0.04      0.07     10608\n",
      "         4.0       0.66      1.00      0.79     24923\n",
      "\n",
      "    accuracy                           0.66     38493\n",
      "   macro avg       0.22      0.21      0.17     38493\n",
      "weighted avg       0.56      0.66      0.53     38493\n",
      "\n",
      "[[    0     0     0    32   171]\n",
      " [    0     0     0    90   485]\n",
      " [    0     0     0   272  1912]\n",
      " [    0     0     1   418 10189]\n",
      " [    0     0     0    90 24833]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ranjangsk/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ranjangsk/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ranjangsk/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, y_train)\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7be6835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.27      0.05      0.09       203\n",
      "         1.0       0.33      0.08      0.13       575\n",
      "         2.0       0.43      0.13      0.20      2184\n",
      "         3.0       0.54      0.35      0.43     10608\n",
      "         4.0       0.75      0.93      0.83     24923\n",
      "\n",
      "    accuracy                           0.71     38493\n",
      "   macro avg       0.46      0.31      0.33     38493\n",
      "weighted avg       0.67      0.71      0.67     38493\n",
      "\n",
      "[[   11    26    48    68    50]\n",
      " [    8    45   150   240   132]\n",
      " [   15    51   282  1134   702]\n",
      " [    6    15   158  3728  6701]\n",
      " [    1     1    22  1763 23136]]\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "xgb_classifier.fit(X_train_tf, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test_tf)\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "print(metrics.confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6833185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
